{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#%%\n",
        "import torch\n",
        "import torchtext.vocab as vocab\n",
        "# %% Code Change because of GloVe download issue\n",
        "# solution provided by Mitchell Miller\n",
        "# glove = vocab.GloVe(name='6B', dim =100)\n",
        "from torchtext.vocab import Vectors\n",
        "\n",
        "class newGloVe(Vectors):\n",
        "    url = {\n",
        "        \"42B\": \"https://huggingface.co/stanfordnlp/glove/resolve/main/glove.42B.300d.zip\",\n",
        "        \"840B\": \"https://huggingface.co/stanfordnlp/glove/resolve/main/glove.840B.300d.zip\",\n",
        "        \"twitter.27B\": \"https://huggingface.co/stanfordnlp/glove/resolve/main/glove.twitter.27B.zip\",\n",
        "        \"6B\": \"https://huggingface.co/stanfordnlp/glove/resolve/main/glove.6B.zip\",\n",
        "    }\n",
        "\n",
        "    def __init__(self, name=\"840B\", dim=300, **kwargs) -> None:\n",
        "        url = self.url[name]\n",
        "        print(f\"Downloading from {url}\")\n",
        "        name = \"glove.{}.{}d.txt\".format(name, str(dim))\n",
        "        super(newGloVe, self).__init__(name, url=url, **kwargs)\n",
        "\n",
        "glove = newGloVe(name='6B', dim=100)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LULN0ubCEJm",
        "outputId": "419e6dbe-001a-4af3-87db-4ee0a9ffe47f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://huggingface.co/stanfordnlp/glove/resolve/main/glove.6B.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [00:04, 189MB/s]                           \n",
            "100%|█████████▉| 400000/400001 [00:20<00:00, 19422.13it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %% number of words and embeddings\n",
        "glove.vectors.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKKq4pAWDsSf",
        "outputId": "16d0631b-4ac8-4c94-b6f5-77d42b5ee6e9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([400001, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%% get an embedding vector\n",
        "def get_embedding_vector(word):\n",
        "    word_index = glove.stoi[word]\n",
        "    emb = glove.vectors[word_index]\n",
        "    return emb\n",
        "\n",
        "get_embedding_vector('chess').shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjYV8fL9FeTH",
        "outputId": "d9952748-715b-431f-fd9d-3bb3c80b5d17"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([100])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%% find closest words from input word\n",
        "def get_closest_words_from_word(word, max_n=5):\n",
        "    word_emb = get_embedding_vector(word)\n",
        "    distances = [(w, torch.dist(word_emb, get_embedding_vector(w)).cpu().item()) for w in glove.itos]\n",
        "    dist_sort_filt = sorted(distances, key=lambda x: x[1])[:max_n]\n",
        "    return dist_sort_filt\n",
        "\n",
        "get_closest_words_from_word('chess')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFekSYLeFiAl",
        "outputId": "39d9a864-54ff-4772-c725-684c7bbc2483"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('chess', 0.0),\n",
              " ('backgammon', 4.379469394683838),\n",
              " ('grandmasters', 4.56368350982666),\n",
              " ('grandmaster', 4.613785743713379),\n",
              " ('scrabble', 4.677640438079834)]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%% find closest words from embedding\n",
        "def get_closest_words_from_embedding(word_emb, max_n=5):\n",
        "    distances = [(w, torch.dist(word_emb, get_embedding_vector(w)).cpu().item()) for w in glove.itos]\n",
        "    dist_sort_filt = sorted(distances, key=lambda x: x[1])[:max_n]\n",
        "    return dist_sort_filt\n",
        "# %% find word analogies\n",
        "# e.g. King is to Queen like Man is to Woman\n",
        "def get_word_analogy(word1, word2, word3, max_n=5):\n",
        "    # logic w1= king, ...\n",
        "    # w2 - w1 + w3 --> w4\n",
        "    word1_emb = get_embedding_vector(word1)\n",
        "    word2_emb = get_embedding_vector(word2)\n",
        "    word3_emb = get_embedding_vector(word3)\n",
        "    word4_emb = word2_emb - word1_emb + word3_emb\n",
        "    analogy = get_closest_words_from_embedding(word4_emb)\n",
        "    return analogy\n",
        "\n",
        "get_word_analogy(word1='sister', word2='brother', word3='nephew')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYrhDisOFj7O",
        "outputId": "c17b641c-c1e2-4fcd-dcfa-a38b89cd39c5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('nephew', 3.9346508979797363),\n",
              " ('brother', 4.407793045043945),\n",
              " ('grandson', 4.478913307189941),\n",
              " ('son', 4.707828521728516),\n",
              " ('uncle', 4.8912482261657715)]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rALtd7vjFmY1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}